## COMMON ##
SEED: 0
USE_CUDA: True
MODEL:
  NAME: Transformer
  KWARGS:
    d_model: 64
    nhead: 4
    dim_feedforward: 256
    dropout: 0
    num_layers: 4
CKPT_PATH: "g2p/checkpoints/transformer.pth"
SEARCH:
  ALGO: GreedySearch
  KWARGS:
    limit: 20

## TRAIN ##
# dataset
NUM_DATA: -1
VALIDATE: True

# training process management
SANITY_CHECK: False
EVAL_TRAIN: False
EVAL_VAL: False

# optimization
BATCH_SIZE: 64
EPOCHS: &epochs 20
OPTIMIZER: Adam
LR:
  LR: 0.001
  SCHEDULER: ExponentialLR
  KWARGS:
    gamma: 1
